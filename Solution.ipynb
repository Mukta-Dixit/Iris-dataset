{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df.species[df.species==\"setosa\"]=0\\ndf.species[df.species==\"versicolor\"]=1\\ndf.species[df.species==\"virginica\"]=2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.species[df.species==\"setosa\"]=0\n",
    "df.species[df.species==\"versicolor\"]=1\n",
    "df.species[df.species==\"virginica\"]=2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "5             5.4          3.9           1.7          0.4     setosa\n",
       "6             4.6          3.4           1.4          0.3     setosa\n",
       "7             5.0          3.4           1.5          0.2     setosa\n",
       "8             4.4          2.9           1.4          0.2     setosa\n",
       "9             4.9          3.1           1.5          0.1     setosa\n",
       "10            5.4          3.7           1.5          0.2     setosa\n",
       "11            4.8          3.4           1.6          0.2     setosa\n",
       "12            4.8          3.0           1.4          0.1     setosa\n",
       "13            4.3          3.0           1.1          0.1     setosa\n",
       "14            5.8          4.0           1.2          0.2     setosa\n",
       "15            5.7          4.4           1.5          0.4     setosa\n",
       "16            5.4          3.9           1.3          0.4     setosa\n",
       "17            5.1          3.5           1.4          0.3     setosa\n",
       "18            5.7          3.8           1.7          0.3     setosa\n",
       "19            5.1          3.8           1.5          0.3     setosa\n",
       "20            5.4          3.4           1.7          0.2     setosa\n",
       "21            5.1          3.7           1.5          0.4     setosa\n",
       "22            4.6          3.6           1.0          0.2     setosa\n",
       "23            5.1          3.3           1.7          0.5     setosa\n",
       "24            4.8          3.4           1.9          0.2     setosa\n",
       "25            5.0          3.0           1.6          0.2     setosa\n",
       "26            5.0          3.4           1.6          0.4     setosa\n",
       "27            5.2          3.5           1.5          0.2     setosa\n",
       "28            5.2          3.4           1.4          0.2     setosa\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,columns=[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species_setosa</th>\n",
       "      <th>species_versicolor</th>\n",
       "      <th>species_virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species_setosa  \\\n",
       "0           5.1          3.5           1.4          0.2               1   \n",
       "1           4.9          3.0           1.4          0.2               1   \n",
       "2           4.7          3.2           1.3          0.2               1   \n",
       "3           4.6          3.1           1.5          0.2               1   \n",
       "4           5.0          3.6           1.4          0.2               1   \n",
       "\n",
       "   species_versicolor  species_virginica  \n",
       "0                   0                  0  \n",
       "1                   0                  0  \n",
       "2                   0                  0  \n",
       "3                   0                  0  \n",
       "4                   0                  0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri=df.drop([\"species_setosa\",\"species_versicolor\",\"species_virginica\"],axis=1)\n",
    "clas=df.drop([\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_attri = preprocessing.normalize(attri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_train,attri_val,clas_train,clas_val=train_test_split(normalized_attri,clas,test_size=0.15,random_state=42)\n",
    "attri_train,attri_test,clas_train,clas_test=train_test_split(attri_train,clas_train,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "#from keras.layers.normalization import BatchNormalization \n",
    "#from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Multilayer neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Network():\n",
    "    model=Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(8,input_dim=4))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #1st hidden layer\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #2nd hidden layer\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #OUtput layer\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mukta/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model=Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 827\n",
      "Trainable params: 827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0001/100, amsgrad=False, clipnorm = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mukta/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 107 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 1.1181 - acc: 0.3458 - val_loss: 1.1304 - val_acc: 0.2609\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 236us/step - loss: 1.1133 - acc: 0.3458 - val_loss: 1.1272 - val_acc: 0.2609\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 263us/step - loss: 1.1102 - acc: 0.3458 - val_loss: 1.1236 - val_acc: 0.2609\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 278us/step - loss: 1.1074 - acc: 0.3458 - val_loss: 1.1204 - val_acc: 0.2609\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 248us/step - loss: 1.1052 - acc: 0.3458 - val_loss: 1.1179 - val_acc: 0.2609\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 220us/step - loss: 1.1029 - acc: 0.3458 - val_loss: 1.1160 - val_acc: 0.2609\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 234us/step - loss: 1.1013 - acc: 0.3458 - val_loss: 1.1142 - val_acc: 0.2609\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 256us/step - loss: 1.0996 - acc: 0.3458 - val_loss: 1.1118 - val_acc: 0.2609\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 224us/step - loss: 1.0975 - acc: 0.3458 - val_loss: 1.1089 - val_acc: 0.2609\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 214us/step - loss: 1.0959 - acc: 0.3458 - val_loss: 1.1056 - val_acc: 0.2609\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 193us/step - loss: 1.0937 - acc: 0.3458 - val_loss: 1.1029 - val_acc: 0.2609\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 262us/step - loss: 1.0914 - acc: 0.3458 - val_loss: 1.1002 - val_acc: 0.2609\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 192us/step - loss: 1.0899 - acc: 0.3458 - val_loss: 1.0971 - val_acc: 0.2609\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 230us/step - loss: 1.0874 - acc: 0.3458 - val_loss: 1.0945 - val_acc: 0.2609\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 311us/step - loss: 1.0854 - acc: 0.4019 - val_loss: 1.0915 - val_acc: 0.6087\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 175us/step - loss: 1.0834 - acc: 0.6729 - val_loss: 1.0883 - val_acc: 0.6087\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 169us/step - loss: 1.0809 - acc: 0.6822 - val_loss: 1.0854 - val_acc: 0.6087\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0845 - acc: 0.625 - 0s 170us/step - loss: 1.0785 - acc: 0.6822 - val_loss: 1.0826 - val_acc: 0.6087\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 177us/step - loss: 1.0761 - acc: 0.6822 - val_loss: 1.0798 - val_acc: 0.6087\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 188us/step - loss: 1.0732 - acc: 0.6822 - val_loss: 1.0768 - val_acc: 0.6087\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 174us/step - loss: 1.0704 - acc: 0.6822 - val_loss: 1.0731 - val_acc: 0.6087\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 196us/step - loss: 1.0669 - acc: 0.6822 - val_loss: 1.0694 - val_acc: 0.6087\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 183us/step - loss: 1.0633 - acc: 0.6822 - val_loss: 1.0654 - val_acc: 0.6087\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 216us/step - loss: 1.0590 - acc: 0.6822 - val_loss: 1.0611 - val_acc: 0.6087\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 168us/step - loss: 1.0545 - acc: 0.6822 - val_loss: 1.0563 - val_acc: 0.6087\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 157us/step - loss: 1.0493 - acc: 0.6822 - val_loss: 1.0510 - val_acc: 0.6087\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 173us/step - loss: 1.0439 - acc: 0.6822 - val_loss: 1.0454 - val_acc: 0.6087\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 203us/step - loss: 1.0376 - acc: 0.6822 - val_loss: 1.0390 - val_acc: 0.6087\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 154us/step - loss: 1.0309 - acc: 0.6822 - val_loss: 1.0317 - val_acc: 0.6087\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 160us/step - loss: 1.0233 - acc: 0.6822 - val_loss: 1.0238 - val_acc: 0.6087\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 0s 172us/step - loss: 1.0148 - acc: 0.6822 - val_loss: 1.0152 - val_acc: 0.6087\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 182us/step - loss: 1.0054 - acc: 0.6822 - val_loss: 1.0056 - val_acc: 0.6087\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 202us/step - loss: 0.9955 - acc: 0.6822 - val_loss: 0.9953 - val_acc: 0.6087\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 178us/step - loss: 0.9838 - acc: 0.6822 - val_loss: 0.9836 - val_acc: 0.6087\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 181us/step - loss: 0.9713 - acc: 0.6822 - val_loss: 0.9708 - val_acc: 0.6087\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 188us/step - loss: 0.9577 - acc: 0.6822 - val_loss: 0.9560 - val_acc: 0.6087\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 206us/step - loss: 0.9427 - acc: 0.6822 - val_loss: 0.9398 - val_acc: 0.6087\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 191us/step - loss: 0.9263 - acc: 0.6822 - val_loss: 0.9218 - val_acc: 0.6087\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 171us/step - loss: 0.9085 - acc: 0.6822 - val_loss: 0.9026 - val_acc: 0.6087\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 172us/step - loss: 0.8891 - acc: 0.6822 - val_loss: 0.8829 - val_acc: 0.6087\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 175us/step - loss: 0.8691 - acc: 0.6822 - val_loss: 0.8610 - val_acc: 0.6087\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 183us/step - loss: 0.8474 - acc: 0.6916 - val_loss: 0.8377 - val_acc: 0.8696\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 167us/step - loss: 0.8264 - acc: 0.7757 - val_loss: 0.8137 - val_acc: 0.8696\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 174us/step - loss: 0.8010 - acc: 0.7477 - val_loss: 0.7898 - val_acc: 0.8696\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 180us/step - loss: 0.7773 - acc: 0.7757 - val_loss: 0.7654 - val_acc: 0.8696\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 182us/step - loss: 0.7534 - acc: 0.8598 - val_loss: 0.7409 - val_acc: 0.8696\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 187us/step - loss: 0.7280 - acc: 0.9065 - val_loss: 0.7165 - val_acc: 0.8696\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 247us/step - loss: 0.7034 - acc: 0.9252 - val_loss: 0.6922 - val_acc: 0.8696\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 172us/step - loss: 0.6791 - acc: 0.8224 - val_loss: 0.6668 - val_acc: 0.8261\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 238us/step - loss: 0.6562 - acc: 0.6636 - val_loss: 0.6431 - val_acc: 0.7391\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 215us/step - loss: 0.6336 - acc: 0.6916 - val_loss: 0.6212 - val_acc: 0.8696\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 223us/step - loss: 0.6131 - acc: 0.8972 - val_loss: 0.6028 - val_acc: 0.8696\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 186us/step - loss: 0.5947 - acc: 0.9626 - val_loss: 0.5861 - val_acc: 0.9565\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 195us/step - loss: 0.5771 - acc: 0.9720 - val_loss: 0.5708 - val_acc: 0.9565\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.5801 - acc: 0.906 - 0s 195us/step - loss: 0.5616 - acc: 0.9439 - val_loss: 0.5553 - val_acc: 0.9565\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 185us/step - loss: 0.5475 - acc: 0.9813 - val_loss: 0.5420 - val_acc: 0.9565\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 197us/step - loss: 0.5350 - acc: 0.9813 - val_loss: 0.5278 - val_acc: 0.9565\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 175us/step - loss: 0.5235 - acc: 0.9626 - val_loss: 0.5157 - val_acc: 0.8696\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 157us/step - loss: 0.5130 - acc: 0.9346 - val_loss: 0.5056 - val_acc: 0.8696\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 164us/step - loss: 0.5032 - acc: 0.9626 - val_loss: 0.4992 - val_acc: 0.9565\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 191us/step - loss: 0.4948 - acc: 0.9626 - val_loss: 0.4921 - val_acc: 0.9565\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 175us/step - loss: 0.4870 - acc: 0.9533 - val_loss: 0.4838 - val_acc: 0.9565\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 220us/step - loss: 0.4790 - acc: 0.9907 - val_loss: 0.4750 - val_acc: 0.9565\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 162us/step - loss: 0.4721 - acc: 0.9720 - val_loss: 0.4677 - val_acc: 0.9565\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 161us/step - loss: 0.4648 - acc: 0.9720 - val_loss: 0.4652 - val_acc: 0.9565\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 160us/step - loss: 0.4591 - acc: 0.9533 - val_loss: 0.4603 - val_acc: 0.9565\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.5385 - acc: 0.968 - 0s 159us/step - loss: 0.4534 - acc: 0.9533 - val_loss: 0.4544 - val_acc: 0.9565\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 168us/step - loss: 0.4463 - acc: 0.9533 - val_loss: 0.4439 - val_acc: 0.9565\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 241us/step - loss: 0.4408 - acc: 0.9813 - val_loss: 0.4372 - val_acc: 0.9565\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 193us/step - loss: 0.4350 - acc: 0.9813 - val_loss: 0.4331 - val_acc: 0.9565\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 208us/step - loss: 0.4302 - acc: 0.9720 - val_loss: 0.4245 - val_acc: 0.9565\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 212us/step - loss: 0.4242 - acc: 0.9626 - val_loss: 0.4201 - val_acc: 0.9565\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 205us/step - loss: 0.4183 - acc: 0.9626 - val_loss: 0.4145 - val_acc: 0.9565\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 161us/step - loss: 0.4133 - acc: 0.9813 - val_loss: 0.4131 - val_acc: 0.9565\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 163us/step - loss: 0.4070 - acc: 0.9907 - val_loss: 0.4101 - val_acc: 0.9565\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 192us/step - loss: 0.4032 - acc: 0.9533 - val_loss: 0.4087 - val_acc: 0.9565\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 193us/step - loss: 0.3972 - acc: 0.9626 - val_loss: 0.3957 - val_acc: 0.9565\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 162us/step - loss: 0.3945 - acc: 0.9626 - val_loss: 0.3879 - val_acc: 0.9130\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 248us/step - loss: 0.3875 - acc: 0.9813 - val_loss: 0.3862 - val_acc: 0.9565\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 153us/step - loss: 0.3817 - acc: 0.9813 - val_loss: 0.3808 - val_acc: 0.9565\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 196us/step - loss: 0.3754 - acc: 0.9813 - val_loss: 0.3811 - val_acc: 0.9565\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 167us/step - loss: 0.3728 - acc: 0.9533 - val_loss: 0.3808 - val_acc: 0.9565\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 171us/step - loss: 0.3659 - acc: 0.9813 - val_loss: 0.3662 - val_acc: 0.9565\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 167us/step - loss: 0.3613 - acc: 0.9720 - val_loss: 0.3605 - val_acc: 0.9565\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 188us/step - loss: 0.3546 - acc: 0.9813 - val_loss: 0.3666 - val_acc: 0.9565\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 159us/step - loss: 0.3506 - acc: 0.9533 - val_loss: 0.3702 - val_acc: 0.9565\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 205us/step - loss: 0.3473 - acc: 0.9439 - val_loss: 0.3630 - val_acc: 0.9565\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 193us/step - loss: 0.3420 - acc: 0.9533 - val_loss: 0.3561 - val_acc: 0.9565\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 175us/step - loss: 0.3350 - acc: 0.9533 - val_loss: 0.3447 - val_acc: 0.9565\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 188us/step - loss: 0.3299 - acc: 0.9720 - val_loss: 0.3341 - val_acc: 0.9565\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 198us/step - loss: 0.3252 - acc: 0.9813 - val_loss: 0.3283 - val_acc: 0.9565\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 184us/step - loss: 0.3192 - acc: 0.9813 - val_loss: 0.3288 - val_acc: 0.9565\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 169us/step - loss: 0.3144 - acc: 0.9813 - val_loss: 0.3261 - val_acc: 0.9565\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 181us/step - loss: 0.3088 - acc: 0.9813 - val_loss: 0.3265 - val_acc: 0.9565\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 226us/step - loss: 0.3087 - acc: 0.9533 - val_loss: 0.3284 - val_acc: 0.9565\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 222us/step - loss: 0.3011 - acc: 0.9626 - val_loss: 0.3118 - val_acc: 0.9565\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 258us/step - loss: 0.2936 - acc: 0.9813 - val_loss: 0.3030 - val_acc: 0.9565\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 246us/step - loss: 0.2909 - acc: 0.9720 - val_loss: 0.2930 - val_acc: 0.9565\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 312us/step - loss: 0.2892 - acc: 0.9626 - val_loss: 0.2980 - val_acc: 0.9565\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 307us/step - loss: 0.2802 - acc: 0.9907 - val_loss: 0.2926 - val_acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f857b57ad68>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(attri_train,clas_train,validation_data=(attri_val,clas_val),batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 120us/step\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(x=attri_test,y=clas_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.9999988079071\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30931907892227173"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
